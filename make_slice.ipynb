{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# X_CH"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5036f4ca0db6584f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "x_ch=360 fits slice"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e07488f2ec416c93"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from astropy.io import fits\n",
    "from astropy.wcs import WCS\n",
    "\n",
    "# 定义FITS文件路径和需要提取的x通道\n",
    "fits_name_12co = \"/Users/naoj306/Desktop/DB/SFP/ORIONA_12CO_21.7arcsec_vel0.1_sph_v1.0.fits\"\n",
    "x_ch = 360\n",
    "\n",
    "# 打开FITS文件\n",
    "with fits.open(fits_name_12co) as hdul:\n",
    "    data = hdul[0].data\n",
    "    original_header = hdul[0].header\n",
    "\n",
    "    # 提取特定x通道的数据切片\n",
    "    data_slice = data[:, :, x_ch]\n",
    "\n",
    "    # 创建一个新的FITS头，不包含任何WCS信息，只包含数据结构信息\n",
    "    header_new = fits.Header()\n",
    "    header_new['SIMPLE'] = True\n",
    "    header_new['BITPIX'] = original_header['BITPIX']\n",
    "    header_new['NAXIS'] = 2\n",
    "    header_new['NAXIS1'] = data_slice.shape[1]\n",
    "    header_new['NAXIS2'] = data_slice.shape[0]\n",
    "    header_new['EXTEND'] = True\n",
    "    header_new['BSCALE'] = original_header['BSCALE']\n",
    "    header_new['BZERO'] = original_header['BZERO']\n",
    "\n",
    "    # 创建新的FITS HDU\n",
    "    hdu_new = fits.PrimaryHDU(data=data_slice, header=header_new)\n",
    "    hdul_new = fits.HDUList([hdu_new])\n",
    "\n",
    "    # 保存新的FITS文件\n",
    "    new_fits_path = '12CO_x360_slice_no_wcs.fits'\n",
    "    hdul_new.writeto(new_fits_path, overwrite=True)\n",
    "\n",
    "print(f\"新的FITS文件已保存在：{new_fits_path}\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bc112e0a0f490471",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "hdu = fits.open('12CO_x360_slice_no_wcs.fits')[0]\n",
    "w = WCS(hdu.header)\n",
    "print(w)\n",
    "print(\"Pixel scale (CDELT):\", w.wcs.cdelt)\n",
    "print(\"Axis units (CUNIT):\", w.wcs.cunit)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c38274911d6fbd98",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "all x_ch save to dir"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9b69cf415e736f68"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import os\n",
    "from astropy.io import fits\n",
    "from astropy.wcs import WCS\n",
    "\n",
    "# 定义FITS文件路径和输出文件夹\n",
    "fits_name_12co = \"/Users/naoj306/Desktop/DB/SFP/ORIONA_12CO_21.7arcsec_vel0.1_sph_v1.0.fits\"\n",
    "output_folder = \"/Users/naoj306/Desktop/find/orion/slice/no_wcs\"\n",
    "\n",
    "# 确保输出文件夹存在\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# 打开FITS文件\n",
    "with fits.open(fits_name_12co) as hdul:\n",
    "    data = hdul[0].data\n",
    "    original_header = hdul[0].header\n",
    "\n",
    "    # 遍历所有x通道\n",
    "    for x_ch in range(data.shape[2]):  # 假设data的第三维是通道数\n",
    "        # 提取特定x通道的数据切片\n",
    "        data_slice = data[:, :, x_ch]\n",
    "\n",
    "        # 创建一个新的FITS头，不包含任何WCS信息，只包含数据结构信息\n",
    "        header_new = fits.Header()\n",
    "        header_new['SIMPLE'] = True\n",
    "        header_new['BITPIX'] = original_header['BITPIX']\n",
    "        header_new['NAXIS'] = 2\n",
    "        header_new['NAXIS1'] = data_slice.shape[1]\n",
    "        header_new['NAXIS2'] = data_slice.shape[0]\n",
    "        header_new['EXTEND'] = True\n",
    "        header_new['BSCALE'] = original_header['BSCALE']\n",
    "        header_new['BZERO'] = original_header['BZERO']\n",
    "\n",
    "        # 创建新的FITS HDU\n",
    "        hdu_new = fits.PrimaryHDU(data=data_slice, header=header_new)\n",
    "        hdul_new = fits.HDUList([hdu_new])\n",
    "\n",
    "        # 生成新的文件名并保存新的FITS文件\n",
    "        new_fits_path = os.path.join(output_folder, f'12CO_x{x_ch}.fits')\n",
    "        hdul_new.writeto(new_fits_path, overwrite=True)\n",
    "\n",
    "        print(f\"新的FITS文件已保存在：{new_fits_path}\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "73c1f379296fb81e",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "median filter, diff, 1 xch"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cccbeaa820c5c746"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# from astropy.io import fits\n",
    "# from astropy.wcs import WCS\n",
    "# from scipy.ndimage import median_filter\n",
    "# \n",
    "# # 定义FITS文件路径\n",
    "# fits_name_12co = \"/Users/naoj306/Desktop/DB/SFP/AquilaRift_12CO_21.7arcsec_vel0.1_sph_v1.0.fits\"\n",
    "# x_ch = 360\n",
    "# \n",
    "# # 打开FITS文件\n",
    "# with fits.open(fits_name_12co) as hdul:\n",
    "#     data = hdul[0].data\n",
    "#     original_header = hdul[0].header\n",
    "# \n",
    "#     # 提取特定x通道的数据切片\n",
    "#     data_slice = data[:, :, x_ch]\n",
    "# \n",
    "#     # 应用3x50 median filter\n",
    "#     filtered_data = median_filter(data_slice, size=(3, 50))\n",
    "#     diff_data = data_slice - filtered_data\n",
    "# \n",
    "#     # 创建通用的新FITS头\n",
    "#     header_new = fits.Header()\n",
    "#     header_new['SIMPLE'] = True\n",
    "#     header_new['BITPIX'] = original_header['BITPIX']\n",
    "#     header_new['NAXIS'] = 2\n",
    "#     header_new['NAXIS1'] = data_slice.shape[1]\n",
    "#     header_new['NAXIS2'] = data_slice.shape[0]\n",
    "#     header_new['EXTEND'] = True\n",
    "#     header_new['BSCALE'] = original_header['BSCALE']\n",
    "#     header_new['BZERO'] = original_header['BZERO']\n",
    "# \n",
    "#     # 创建滤波数据的FITS HDU并保存\n",
    "#     hdu_filtered = fits.PrimaryHDU(data=filtered_data, header=header_new)\n",
    "#     hdul_filtered = fits.HDUList([hdu_filtered])\n",
    "#     filtered_fits_path = '12CO_x360_slice_filtered.fits'\n",
    "#     hdul_filtered.writeto(filtered_fits_path, overwrite=True)\n",
    "# \n",
    "#     # 创建差异数据的FITS HDU并保存\n",
    "#     hdu_diff = fits.PrimaryHDU(data=diff_data, header=header_new)\n",
    "#     hdul_diff = fits.HDUList([hdu_diff])\n",
    "#     diff_fits_path = '12CO_x360_slice_diff.fits'\n",
    "#     hdul_diff.writeto(diff_fits_path, overwrite=True)\n",
    "# \n",
    "# print(f\"已保存filtered fits在：{filtered_fits_path}\")\n",
    "# print(f\"已保存diff fits在：{diff_fits_path}\")\n",
    "# # hdu = fits.open('12CO_x360_slice_no_wcs_diff.fits')[0]\n",
    "# # w = WCS(hdu.header)\n",
    "# # print(w)\n",
    "# # print(\"Pixel scale (CDELT):\", w.wcs.cdelt)\n",
    "# # print(\"Axis units (CUNIT):\", w.wcs.cunit)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d77f03752a225462"
  },
  {
   "cell_type": "markdown",
   "source": [
    "all x_ch, filter, diff "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "61749c15e6eda919"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# from astropy.io import fits\n",
    "# from astropy.wcs import WCS\n",
    "# from scipy.ndimage import median_filter\n",
    "# import os\n",
    "# \n",
    "# # 定义FITS文件路径\n",
    "# fits_name_12co = \"/Users/naoj306/Desktop/DB/SFP/AquilaRift_12CO_21.7arcsec_vel0.1_sph_v1.0.fits\"\n",
    "# \n",
    "# # 创建目录保存filtered和diff文件\n",
    "# filtered_dir = \"/Users/naoj306/Desktop/find/slice_no_wcs_filt_1-99\"  # 替换为你的实际路径\n",
    "# diff_dir = \"/Users/naoj306/Desktop/find/slice_no_wcs_diff_1-99\"  # 替换为你的实际路径\n",
    "# os.makedirs(filtered_dir, exist_ok=True)\n",
    "# os.makedirs(diff_dir, exist_ok=True)\n",
    "# \n",
    "# # 打开FITS文件\n",
    "# with fits.open(fits_name_12co) as hdul:\n",
    "#     data = hdul[0].data\n",
    "#     original_header = hdul[0].header\n",
    "# \n",
    "#     # 获取x通道的总数\n",
    "#     x_total = data.shape[2]\n",
    "# \n",
    "#     # 遍历所有的x通道\n",
    "#     for x_ch in range(x_total):\n",
    "#         # 提取特定x通道的数据切片\n",
    "#         data_slice = data[:, :, x_ch]\n",
    "# \n",
    "#         # 应用3x50 median filter\n",
    "#         filtered_data = median_filter(data_slice, size=(1, 99)) # filter size\n",
    "#         diff_data = data_slice - filtered_data\n",
    "# \n",
    "#         # 创建通用的新FITS头\n",
    "#         header_new = fits.Header()\n",
    "#         header_new['SIMPLE'] = True\n",
    "#         header_new['BITPIX'] = original_header['BITPIX']\n",
    "#         header_new['NAXIS'] = 2\n",
    "#         header_new['NAXIS1'] = data_slice.shape[1]\n",
    "#         header_new['NAXIS2'] = data_slice.shape[0]\n",
    "#         header_new['EXTEND'] = True\n",
    "#         header_new['BSCALE'] = original_header['BSCALE']\n",
    "#         header_new['BZERO'] = original_header['BZERO']\n",
    "# \n",
    "#         # 创建滤波数据的FITS HDU并保存\n",
    "#         hdu_filtered = fits.PrimaryHDU(data=filtered_data, header=header_new)\n",
    "#         hdul_filtered = fits.HDUList([hdu_filtered])\n",
    "#         filtered_fits_path = os.path.join(filtered_dir, f'12CO_x{x_ch}_slice_filtered.fits')\n",
    "#         hdul_filtered.writeto(filtered_fits_path, overwrite=True)\n",
    "# \n",
    "#         # 创建差异数据的FITS HDU并保存\n",
    "#         hdu_diff = fits.PrimaryHDU(data=diff_data, header=header_new)\n",
    "#         hdul_diff = fits.HDUList([hdu_diff])\n",
    "#         diff_fits_path = os.path.join(diff_dir, f'12CO_x{x_ch}_slice_diff.fits')\n",
    "#         hdul_diff.writeto(diff_fits_path, overwrite=True)\n",
    "# \n",
    "#         print(f\"已保存filtered fits在：{filtered_fits_path}\")\n",
    "#         print(f\"已保存diff fits在：{diff_fits_path}\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "28e09df3d2f951b5",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "diff median again"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e1e8e0102933184f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# from astropy.io import fits\n",
    "# from scipy.ndimage import median_filter\n",
    "# import os\n",
    "# \n",
    "# # 定义已存在的diff文件的目录和新的输出目录\n",
    "# diff_dir = \"/Users/naoj306/Desktop/find/slice_no_wcs_diff_1-99\"\n",
    "# new_filtered_dir = \"/Users/naoj306/Desktop/find/slice_no_wcs_diff_1-99_fil_3-3\"  # 修改为你想保存新文件的路径\n",
    "# os.makedirs(new_filtered_dir, exist_ok=True)\n",
    "# \n",
    "# # 获取diff目录中所有的FITS文件\n",
    "# diff_files = [f for f in os.listdir(diff_dir) if f.endswith('.fits')]\n",
    "# \n",
    "# # 遍历所有文件并应用median filter\n",
    "# for file in diff_files:\n",
    "#     file_path = os.path.join(diff_dir, file)\n",
    "#     # 打开FITS文件\n",
    "#     with fits.open(file_path) as hdul:\n",
    "#         data = hdul[0].data\n",
    "#         header = hdul[0].header\n",
    "# \n",
    "#         # 应用3x3的median filter\n",
    "#         filtered_data = median_filter(data, size=(3, 3))\n",
    "# \n",
    "#         # 创建新的FITS文件\n",
    "#         hdu_new_filtered = fits.PrimaryHDU(data=filtered_data, header=header)\n",
    "#         hdul_new_filtered = fits.HDUList([hdu_new_filtered])\n",
    "#         new_filtered_path = os.path.join(new_filtered_dir, file)\n",
    "# \n",
    "#         # 写入新的FITS文件\n",
    "#         hdul_new_filtered.writeto(new_filtered_path, overwrite=True)\n",
    "# \n",
    "#         print(f\"Processed and saved new filtered FITS at: {new_filtered_path}\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "62c1765a9dd63dd2",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "nonan filter 1 xch"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8af675e64643dde5"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from astropy.io import fits\n",
    "import numpy as np\n",
    "from scipy.ndimage import generic_filter\n",
    "\n",
    "# 定义FITS文件路径\n",
    "fits_name_12co = \"/Users/naoj306/Desktop/DB/SFP/AquilaRift_12CO_21.7arcsec_vel0.1_sph_v1.0.fits\"\n",
    "x_ch = 1\n",
    "\n",
    "# 打开FITS文件\n",
    "with fits.open(fits_name_12co) as hdul:\n",
    "    data = hdul[0].data\n",
    "    original_header = hdul[0].header\n",
    "\n",
    "    # 提取特定x通道的数据切片\n",
    "    data_slice = data[:, :, x_ch]\n",
    "\n",
    "    # 自定义的处理NaN的中值滤波函数\n",
    "    def nanmedian_filter(data):\n",
    "        return np.nanmedian(data)\n",
    "\n",
    "    # 应用3x50 median filter，并自动忽略NaN\n",
    "    filtered_data = generic_filter(data_slice, nanmedian_filter, size=(1, 50))\n",
    "    diff_data = data_slice - filtered_data\n",
    "\n",
    "    # 创建通用的新FITS头\n",
    "    header_new = fits.Header()\n",
    "    header_new['SIMPLE'] = True\n",
    "    header_new['BITPIX'] = original_header['BITPIX']\n",
    "    header_new['NAXIS'] = 2\n",
    "    header_new['NAXIS1'] = data_slice.shape[1]\n",
    "    header_new['NAXIS2'] = data_slice.shape[0]\n",
    "    header_new['EXTEND'] = True\n",
    "    header_new['BSCALE'] = original_header['BSCALE']\n",
    "    header_new['BZERO'] = original_header['BZERO']\n",
    "\n",
    "    # 创建滤波数据的FITS HDU并保存\n",
    "    hdu_filtered = fits.PrimaryHDU(data=filtered_data, header=header_new)\n",
    "    hdul_filtered = fits.HDUList([hdu_filtered])\n",
    "    filtered_fits_path = '12CO_x360_slice_filtered_1.fits'\n",
    "    hdul_filtered.writeto(filtered_fits_path, overwrite=True)\n",
    "\n",
    "    # 创建差异数据的FITS HDU并保存\n",
    "    hdu_diff = fits.PrimaryHDU(data=diff_data, header=header_new)\n",
    "    hdul_diff = fits.HDUList([hdu_diff])\n",
    "    diff_fits_path = '12CO_x360_slice_diff_1.fits'\n",
    "    hdul_diff.writeto(diff_fits_path, overwrite=True)\n",
    "\n",
    "print(f\"已保存filtered fits在：{filtered_fits_path}\")\n",
    "print(f\"已保存diff fits在：{diff_fits_path}\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "85d5abfba061284c",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import aplpy\n",
    "from astropy.wcs import WCS\n",
    "import astropy.units as u\n",
    "\n",
    "hdu = fits.open(\"12CO_x360_slice_diff_1.fits\")[0]  # 普通は [0] です。\n",
    "w = WCS(hdu)\n",
    "print(w)\n",
    "print(\"Pixel scale (CDELT):\", w.wcs.cdelt)\n",
    "print(\"Axis units (CUNIT):\", w.wcs.cunit)\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "f = aplpy.FITSFigure(hdu, slices=[0], convention='wells', figure=fig)\n",
    "f.show_colorscale(cmap=\"Greys\", aspect=\"equal\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a5f08cc074a5a484",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "nonan filter all xch"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e4c0cb19c1e25534"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from astropy.io import fits\n",
    "import numpy as np\n",
    "from scipy.ndimage import generic_filter\n",
    "import os\n",
    "\n",
    "# 定义FITS文件路径\n",
    "fits_name_12co = \"/Users/naoj306/Desktop/DB/SFP/ORIONA_12CO_21.7arcsec_vel0.1_sph_v1.0.fits\"\n",
    "# 定义输出目录\n",
    "# filtered_dir = \"/Users/naoj306/Desktop/find/slice_no_wcs_filt_1-99_nonan\"\n",
    "diff_dir = \"/Users/naoj306/Desktop/find/orion_12/slice/vy/no_wcs_diff_1-50_nonan\"\n",
    "\n",
    "# 确保输出目录存在\n",
    "# os.makedirs(filtered_dir, exist_ok=True)\n",
    "os.makedirs(diff_dir, exist_ok=True)\n",
    "\n",
    "# 打开FITS文件\n",
    "with fits.open(fits_name_12co) as hdul:\n",
    "    data = hdul[0].data\n",
    "    original_header = hdul[0].header\n",
    "    num_x_ch = data.shape[2]  # 获取x通道的数量\n",
    "\n",
    "    # 循环处理每个x通道\n",
    "    for x_ch in range(num_x_ch):\n",
    "        data_slice = data[:, :, x_ch]\n",
    "\n",
    "        # 自定义的处理NaN的中值滤波函数\n",
    "        def nanmedian_filter(data):\n",
    "            return np.nanmedian(data)\n",
    "\n",
    "        # 应用1x99 median filter，并自动忽略NaN\n",
    "        filtered_data = generic_filter(data_slice, nanmedian_filter, size=(1, 50))\n",
    "        diff_data = data_slice - filtered_data\n",
    "\n",
    "        # 创建通用的新FITS头\n",
    "        header_new = fits.Header()\n",
    "        header_new['SIMPLE'] = True\n",
    "        header_new['BITPIX'] = original_header['BITPIX']\n",
    "        header_new['NAXIS'] = 2\n",
    "        header_new['NAXIS1'] = data_slice.shape[1]\n",
    "        header_new['NAXIS2'] = data_slice.shape[0]\n",
    "        header_new['EXTEND'] = True\n",
    "        header_new['BSCALE'] = original_header['BSCALE']\n",
    "        header_new['BZERO'] = original_header['BZERO']\n",
    "\n",
    "        # 创建滤波数据的FITS HDU并保存\n",
    "        # hdu_filtered = fits.PrimaryHDU(data=filtered_data, header=header_new)\n",
    "        # filtered_fits_path = os.path.join(filtered_dir, f'12CO_x{x_ch}_slice_filtered_nonan.fits')\n",
    "        # hdu_filtered.writeto(filtered_fits_path, overwrite=True)\n",
    "\n",
    "        # 创建差异数据的FITS HDU并保存\n",
    "        hdu_diff = fits.PrimaryHDU(data=diff_data, header=header_new)\n",
    "        diff_fits_path = os.path.join(diff_dir, f'12CO_x{x_ch}_slice_diff_nonan.fits')\n",
    "        hdu_diff.writeto(diff_fits_path, overwrite=True)\n",
    "\n",
    "        # print(f\"已保存filtered fits在：{filtered_fits_path}\")\n",
    "        print(f\"已保存diff fits在：{diff_fits_path}\")\n",
    "\n",
    "        \n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b1fa293f16e80f2b",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "diff nonan filter again"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7be037ddf3d32b16"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from astropy.io import fits\n",
    "from scipy.ndimage import generic_filter\n",
    "import os\n",
    "\n",
    "# 定义已存在的diff文件的目录和新的输出目录\n",
    "diff_dir = \"/Users/naoj306/Desktop/find/orion_12/slice/vy/no_wcs_diff_1-50_nonan\"\n",
    "new_filtered_dir = \"/Users/naoj306/Desktop/find/orion_12/slice/vy/no_wcs_diff_1-50_3-3_nonan\"  \n",
    "os.makedirs(new_filtered_dir, exist_ok=True)\n",
    "\n",
    "# 获取diff目录中所有的FITS文件\n",
    "diff_files = [f for f in os.listdir(diff_dir) if f.endswith('.fits')]\n",
    "\n",
    "def nanmedian_filter(data):\n",
    "    return np.nanmedian(data)\n",
    "\n",
    "# 遍历所有文件并应用median filter\n",
    "for file in diff_files:\n",
    "    file_path = os.path.join(diff_dir, file)\n",
    "    # 打开FITS文件\n",
    "    with fits.open(file_path) as hdul:\n",
    "        data = hdul[0].data\n",
    "        header = hdul[0].header\n",
    "\n",
    "        # 应用3x3的median filter\n",
    "        filtered_data = generic_filter(data, nanmedian_filter, size=(3, 3))\n",
    "\n",
    "        # 创建新的FITS文件\n",
    "        hdu_new_filtered = fits.PrimaryHDU(data=filtered_data, header=header)\n",
    "        hdul_new_filtered = fits.HDUList([hdu_new_filtered])\n",
    "        new_filtered_path = os.path.join(new_filtered_dir, file)\n",
    "\n",
    "        # 写入新的FITS文件\n",
    "        hdul_new_filtered.writeto(new_filtered_path, overwrite=True)\n",
    "\n",
    "        print(f\"Processed and saved new filtered FITS at: {new_filtered_path}\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b24e7ea00d0100b0",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "# Y_CH"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "482cbd47d9572c4e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "all y_ch save to dir"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1604e6f2dbd8739"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import os\n",
    "from astropy.io import fits\n",
    "\n",
    "# 定义FITS文件路径和输出文件夹\n",
    "fits_name_12co = \"/Users/naoj306/Desktop/DB/SFP/ORIONA_12CO_21.7arcsec_vel0.1_sph_v1.0.fits\"\n",
    "output_folder = \"/Users/naoj306/Desktop/find/orion_12/slice/xv/no_wcs\"\n",
    "\n",
    "# 确保输出文件夹存在\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# 打开FITS文件\n",
    "with fits.open(fits_name_12co) as hdul:\n",
    "    data = hdul[0].data\n",
    "    original_header = hdul[0].header\n",
    "\n",
    "    # 遍历所有y通道\n",
    "    for y_ch in range(data.shape[1]):  # 更新循环，现在遍历第二维（y通道）\n",
    "        # 提取特定y通道的数据切片\n",
    "        data_slice = data[:, y_ch, :]  # 更新数据切片，使其沿第二维切片\n",
    "\n",
    "        # 创建一个新的FITS头，不包含任何WCS信息，只包含数据结构信息\n",
    "        header_new = fits.Header()\n",
    "        header_new['SIMPLE'] = True\n",
    "        header_new['BITPIX'] = original_header['BITPIX']\n",
    "        header_new['NAXIS'] = 2\n",
    "        header_new['NAXIS1'] = data_slice.shape[1]  # 注意这里维度对应的变化\n",
    "        header_new['NAXIS2'] = data_slice.shape[0]\n",
    "        header_new['EXTEND'] = True\n",
    "        header_new['BSCALE'] = original_header['BSCALE']\n",
    "        header_new['BZERO'] = original_header['BZERO']\n",
    "\n",
    "        # 创建新的FITS HDU\n",
    "        hdu_new = fits.PrimaryHDU(data=data_slice, header=header_new)\n",
    "        hdul_new = fits.HDUList([hdu_new])\n",
    "\n",
    "        # 生成新的文件名并保存新的FITS文件\n",
    "        new_fits_path = os.path.join(output_folder, f'12CO_y{y_ch}.fits')\n",
    "        hdul_new.writeto(new_fits_path, overwrite=True)\n",
    "\n",
    "        print(f\"新的FITS文件已保存在：{new_fits_path}\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "10c43f0aef619f95",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "all filter, diff nonan"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bc0c37b0f6961f89"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from astropy.io import fits\n",
    "import numpy as np\n",
    "from scipy.ndimage import generic_filter\n",
    "import os\n",
    "\n",
    "# 定义FITS文件路径\n",
    "fits_name_12co = \"/Users/naoj306/Desktop/DB/SFP/ORIONA_12CO_21.7arcsec_vel0.1_sph_v1.0.fits\"\n",
    "# 定义输出目录\n",
    "# filtered_dir = \"/Users/naoj306/Desktop/find/slice_no_wcs_filt_1-99_nonan\"\n",
    "diff_dir = \"/Users/naoj306/Desktop/find/orion_12/slice/xv/no_wcs_diff_1-99_nonan\"\n",
    "\n",
    "# 确保输出目录存在\n",
    "# os.makedirs(filtered_dir, exist_ok=True)\n",
    "os.makedirs(diff_dir, exist_ok=True)\n",
    "\n",
    "# 打开FITS文件\n",
    "with fits.open(fits_name_12co) as hdul:\n",
    "    data = hdul[0].data\n",
    "    original_header = hdul[0].header\n",
    "    num_y_ch = data.shape[1]  # 更新，获取y通道的数量\n",
    "\n",
    "    # 循环处理每个y通道\n",
    "    for y_ch in range(num_y_ch):\n",
    "        data_slice = data[:, y_ch, :]  # 更新，沿第二维切片\n",
    "\n",
    "        # 自定义的处理NaN的中值滤波函数\n",
    "        def nanmedian_filter(data):\n",
    "            return np.nanmedian(data)\n",
    "\n",
    "        # 应用1x99 median filter，并自动忽略NaN\n",
    "        filtered_data = generic_filter(data_slice, nanmedian_filter, size=(1, 99))\n",
    "        diff_data = data_slice - filtered_data\n",
    "\n",
    "        # 创建通用的新FITS头\n",
    "        header_new = fits.Header()\n",
    "        header_new['SIMPLE'] = True\n",
    "        header_new['BITPIX'] = original_header['BITPIX']\n",
    "        header_new['NAXIS'] = 2\n",
    "        header_new['NAXIS1'] = data_slice.shape[1]\n",
    "        header_new['NAXIS2'] = data_slice.shape[0]\n",
    "        header_new['EXTEND'] = True\n",
    "        header_new['BSCALE'] = original_header['BSCALE']\n",
    "        header_new['BZERO'] = original_header['BZERO']\n",
    "\n",
    "        # # 创建滤波数据的FITS HDU并保存\n",
    "        # hdu_filtered = fits.PrimaryHDU(data=filtered_data, header=header_new)\n",
    "        # filtered_fits_path = os.path.join(filtered_dir, f'12CO_y{y_ch}_slice_filtered_nonan.fits')\n",
    "        # hdu_filtered.writeto(filtered_fits_path, overwrite=True)\n",
    "\n",
    "        # 创建差异数据的FITS HDU并保存\n",
    "        hdu_diff = fits.PrimaryHDU(data=diff_data, header=header_new)\n",
    "        diff_fits_path = os.path.join(diff_dir, f'12CO_y{y_ch}_slice_diff_nonan.fits')\n",
    "        hdu_diff.writeto(diff_fits_path, overwrite=True)\n",
    "\n",
    "        # print(f\"已保存filtered fits在：{filtered_fits_path}\")\n",
    "        print(f\"已保存diff fits在：{diff_fits_path}\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "afdcba531eb4888e",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "b1bf7c8419bc6764"
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "# plot image\n",
    "\n",
    "slice origin with wcs axis"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d9800eaede64e019"
  },
  {
   "cell_type": "markdown",
   "source": [
    "HEADER: ESPECIALLY FOR ORION"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c7d48b82865fb2eb"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from astropy.io import fits\n",
    "from astropy.wcs import WCS\n",
    "\n",
    "# Load the FITS header\n",
    "fits_name = \"/Users/naoj306/Desktop/DB/SFP/ORIONA_12CO_21.7arcsec_vel0.1_sph_v1.0.fits\"\n",
    "\n",
    "with fits.open(fits_name, mode='update') as hdul:\n",
    "    hdu = hdul[0]\n",
    "    header = hdu.header\n",
    "\n",
    "    # Print original CTYPE values\n",
    "    print(\"Original CTYPE1:\", header['CTYPE1'])\n",
    "    print(\"Original CTYPE2:\", header['CTYPE2'])\n",
    "\n",
    "    # Modify the CTYPE values\n",
    "    header['CTYPE1'] = 'RA---TAN'\n",
    "    header['CTYPE2'] = 'DEC--TAN'\n",
    "\n",
    "    # Save the changes\n",
    "    hdul.flush()  # Important: This saves the modified header back to the file\n",
    "\n",
    "# Try initializing the WCS again\n",
    "try:\n",
    "    wcs = WCS(header)\n",
    "    print(\"WCS initialized successfully:\", wcs)\n",
    "except Exception as e:\n",
    "    print(\"Error initializing WCS:\", e)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6aae682f15e0dc0d",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "VY"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fafca5a2b182fd58"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from astropy.io import fits\n",
    "from astropy.wcs import WCS\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def generate_and_save_yv_slices(fits_name, output_path):\n",
    "    with fits.open(fits_name) as hdul:\n",
    "        data = hdul[0].data\n",
    "        header = hdul[0].header\n",
    "    wcs = WCS(header)\n",
    "\n",
    "    # 转换速度单位到km/s\n",
    "    v_size = header['NAXIS3']\n",
    "    v_crpix = header['CRPIX3']\n",
    "    v_crval = header['CRVAL3'] / 1000.0  # m/s to km/s\n",
    "    v_cdelt = header['CDELT3'] / 1000.0  # m/s to km/s\n",
    "    velocities = (np.arange(v_size) - (v_crpix - 1)) * v_cdelt + v_crval\n",
    "\n",
    "    # 获取分子线信息\n",
    "    molecule = header.get('LINE', 'Unknown Molecule')\n",
    "\n",
    "    # 遍历X轴（RA方向）\n",
    "    for x_index in range(data.shape[2]):\n",
    "        ra_deg = wcs.wcs_pix2world([[x_index, 0, 0]], 0)[0][0]\n",
    "\n",
    "        dec_pixels = np.arange(data.shape[1])\n",
    "        ra_pixels = np.full_like(dec_pixels, x_index)\n",
    "        world_coords = wcs.all_pix2world(np.vstack([ra_pixels, dec_pixels, np.zeros_like(dec_pixels)]).T, 0)\n",
    "        dec_deg = world_coords[:, 1]  # 获取赤纬度数\n",
    "\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(7, 15))\n",
    "        yv_data = data[:, :, x_index].T  # 转置以匹配绘图的轴向\n",
    "        ax.set_position([0.1, 0.1, 0.7, 0.8])\n",
    "        cax = fig.add_axes([0.82, 0.1, 0.03, 0.8])\n",
    "        im = ax.imshow(yv_data, origin='lower', aspect='auto',\n",
    "                       extent=[velocities[0], velocities[-1], dec_deg.min(), dec_deg.max()],\n",
    "                       cmap='viridis')\n",
    "        ax.set_xlabel(\"Velocity (km/s)\")\n",
    "        ax.set_ylabel(\"Dec (degrees)\")\n",
    "        ax.set_title(f\"{molecule} at {ra_deg:.4f} degree\")\n",
    "\n",
    "        cbar = plt.colorbar(im, cax=cax)\n",
    "        cbar.set_label('Temperature (K)', rotation=270, labelpad=15)\n",
    "\n",
    "        plt.savefig(f\"{output_path}/slice_xch{x_index:03d}_ra{ra_deg:.4f}.png\")\n",
    "        # plt.show()\n",
    "        plt.close()\n",
    "        print(f\"Saved: slice_xch{x_index:03d}_ra{ra_deg:.4f}.png\")\n",
    "\n",
    " \n",
    "fits_name = \"/Users/naoj306/Desktop/DB/SFP/ORIONA_12CO_21.7arcsec_vel0.1_sph_v1.0.fits\"\n",
    "output_path = \"/Users/naoj306/Desktop/find/orion_12/images/slice_origin_wcs_axis/vy\"\n",
    "generate_and_save_yv_slices(fits_name, output_path)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ad75fc623bfd571a",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "XV"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aea009fccb48a87c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from astropy.io import fits\n",
    "from astropy.wcs import WCS\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def generate_and_save_xv_slices(fits_name, output_path):\n",
    "    with fits.open(fits_name) as hdul:\n",
    "        data = hdul[0].data\n",
    "        header = hdul[0].header\n",
    "    wcs = WCS(header)\n",
    "\n",
    "    # Velocity unit conversion to km/s\n",
    "    v_size = header['NAXIS3']\n",
    "    v_crpix = header['CRPIX3']\n",
    "    v_crval = header['CRVAL3'] / 1000.0  # Convert from m/s to km/s\n",
    "    v_cdelt = header['CDELT3'] / 1000.0  # Convert from m/s to km/s\n",
    "    velocities = (np.arange(v_size) - (v_crpix - 1)) * v_cdelt + v_crval\n",
    "\n",
    "    # Get molecule information\n",
    "    molecule = header.get('LINE', 'Unknown Molecule')\n",
    "\n",
    "    for y_index in range(data.shape[1]):\n",
    "        dec_deg = wcs.wcs_pix2world([[0, y_index, 0]], 0)[0][1]\n",
    "\n",
    "        # Directly select the slice without transposing\n",
    "        xv_data = data[:, y_index, :]\n",
    "\n",
    "        ra_size = data.shape[2]\n",
    "        ra_crpix = header['CRPIX1']\n",
    "        ra_crval = header['CRVAL1']  # Already in degrees\n",
    "        ra_cdelt = header['CDELT1']  # Already in degrees\n",
    "        ras = (np.arange(ra_size) - (ra_crpix - 1)) * ra_cdelt + ra_crval\n",
    "\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(13, 4))\n",
    "        im = ax.imshow(xv_data, origin='lower', aspect='auto',\n",
    "                       extent=[ras.min(), ras.max(), velocities[0], velocities[-1]],\n",
    "                       cmap='viridis')\n",
    "        ax.set_xlabel(\"RA (degrees)\")\n",
    "        ax.set_ylabel(\"Velocity (km/s)\")\n",
    "        ax.set_title(f\"{molecule} at DEC {dec_deg:.4f} degree\")\n",
    "\n",
    "        cbar = plt.colorbar(im, ax=ax, pad=0.1)\n",
    "        cbar.set_label('Temperature (K)', rotation=270, labelpad=15)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"{output_path}/slice_ych{y_index:03d}_dec{dec_deg:.4f}.png\")\n",
    "        # plt.show()\n",
    "        plt.close()\n",
    "        print(f\"Saved: slice_ych{y_index:03d}_dec{dec_deg:.4f}.png\")\n",
    "\n",
    "\n",
    "fits_name = \"/Users/naoj306/Desktop/DB/SFP/ORIONA_12CO_21.7arcsec_vel0.1_sph_v1.0.fits\"\n",
    "output_path = \"/Users/naoj306/Desktop/find/orion_12/images/slice_origin_wcs_axis/xv_1\"\n",
    "generate_and_save_xv_slices(fits_name, output_path)\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "c15db290f484be8f",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "ac5fdf8c185ab0ae",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "beef2f520b95f985"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
