{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "selected fila on origin vy fits, xch slider"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "27006a74ef43c4ba"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from ipywidgets import widgets\n",
    "from IPython.display import display\n",
    "from astropy.io import fits\n",
    "from astropy.wcs import WCS\n",
    "from datetime import datetime\n",
    "\n",
    "from astropy.io import fits\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "\n",
    "def read_structure_file(file_path):\n",
    "    \"\"\"读取CSV文件并解析数据，以便可视化\"\"\"\n",
    "    df = pd.read_csv(file_path)\n",
    "    structures = {}\n",
    "    for _, row in df.iterrows():\n",
    "        x_coord = int(row['x channel'])  # 确保x channel在CSV中正确命名\n",
    "        ymin = int(row['ymin'])\n",
    "        ymax = int(row['ymax'])\n",
    "        vmin = int(row['vmin'])\n",
    "        vmax = int(row['vmax'])\n",
    "        length = float(row['length'])  # 确保'length'列存在且为数值类型\n",
    "        binary_class = int(row['class'])  # 确保'class'列存在且为整数类型\n",
    "\n",
    "        # # 只添加长度大于15的结构\n",
    "        # if binary_class == 1: \n",
    "        #     if x_coord not in structures:\n",
    "        #         structures[x_coord] = []\n",
    "        #     # 将结构存储为元组，方便后续处理\n",
    "        if x_coord not in structures:\n",
    "            structures[x_coord] = []\n",
    "        structures[x_coord].append((ymin, ymax, vmin, vmax, length))\n",
    "\n",
    "    return structures\n",
    "\n",
    "\n",
    "def load_fits_slice_with_structures(x_ch, fits_path, structures):\n",
    "    \"\"\"Load a specific x-channel slice from a FITS file, display it using Plotly, and overlay structure ranges.\"\"\"\n",
    "    with fits.open(fits_path) as hdul:\n",
    "        data = hdul[0].data\n",
    "        wcs = WCS(hdul[0].header)\n",
    "        data_slice = data[:, :, x_ch].T\n",
    "\n",
    "    fig = px.imshow(data_slice, origin='lower', labels={'color': 'Intensity'},\n",
    "                    color_continuous_scale='gray', aspect='equal')\n",
    "    fig.update_layout(title=f\"FITS Slice at X Channel: {x_ch}\")\n",
    "\n",
    "    # Overlay structures from CSV if available for this x channel\n",
    "    if x_ch in structures:\n",
    "        for ymin, ymax, vmin, vmax, length in structures[x_ch]:\n",
    "            # Add a rectangle for each structure\n",
    "            fig.add_shape(type=\"rect\",\n",
    "                          x0=vmin, y0=ymin, x1=vmax, y1=ymax,\n",
    "                          line=dict(color=\"red\"),\n",
    "                          fillcolor=\"rgba(0,0,0,0)\")\n",
    "\n",
    "    return fig\n",
    "\n",
    "def analyze_structures(file_path, fits_path):\n",
    "    structures = read_structure_file(file_path)\n",
    "    x_channels = sorted(structures.keys())\n",
    "\n",
    "    x_slider = widgets.IntSlider(\n",
    "        value=x_channels[0],\n",
    "        min=min(x_channels),\n",
    "        max=max(x_channels),\n",
    "        step=1,\n",
    "        description='X Channel:',\n",
    "        continuous_update=False\n",
    "    )\n",
    "    \n",
    "    plot_container = widgets.Output()\n",
    "    \n",
    "    def update_plot(change):\n",
    "        x_ch = change.new\n",
    "        with plot_container:\n",
    "            plot_container.clear_output(wait=True)\n",
    "            fig = load_fits_slice_with_structures(x_ch, fits_path, structures)\n",
    "            fig.show()\n",
    "    \n",
    "    x_slider.observe(update_plot, names='value')\n",
    "    display(x_slider, plot_container)\n",
    "\n",
    "# Set the paths\n",
    "csv_path = '/Users/naoj306/Desktop/find_data/aquila_12/location/nonan_diff_1-99_3-3/location.csv'\n",
    "fits_path = \"/Users/naoj306/Desktop/DB/SFP/AquilaRift_12CO_21.7arcsec_vel0.1_sph_v1.0.fits\"\n",
    "analyze_structures(csv_path, fits_path)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "803931154397e1eb",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "selected fila on origin vy fits, all xch image"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a20867a460c448c0"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.io import fits\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def read_structure_file(file_path):\n",
    "    \"\"\"从CSV文件读取并解析数据\"\"\"\n",
    "    df = pd.read_csv(file_path)\n",
    "    structures = {}\n",
    "    for _, row in df.iterrows():\n",
    "        x_coord = int(row['x channel'])\n",
    "        ymin = int(row['ymin'])\n",
    "        ymax = int(row['ymax'])\n",
    "        vmin = int(row['vmin'])\n",
    "        vmax = int(row['vmax'])\n",
    "        length = float(row['length'])\n",
    "        binary_class = int(row['class'])\n",
    "        if x_coord not in structures:\n",
    "            structures[x_coord] = []\n",
    "        # 存储结构及其长度和二分分类\n",
    "        structures[x_coord].append((ymin, ymax, vmin, vmax, length, binary_class))\n",
    "    return structures\n",
    "\n",
    "def save_fits_slice_with_structures(x_ch, fits_path, structures, output_directory):\n",
    "    \"\"\"处理FITS切片，添加结构，保存为PNG\"\"\"\n",
    "    with fits.open(fits_path) as hdul:\n",
    "        data = hdul[0].data\n",
    "        wcs = WCS(hdul[0].header)\n",
    "        data_slice = data[:, :, x_ch].T\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.imshow(data_slice, origin='lower', cmap='gray', aspect='auto')\n",
    "\n",
    "    # 如果此x通道有结构，绘制它们\n",
    "    if x_ch in structures:\n",
    "        for ymin, ymax, vmin, vmax, length, binary_class in structures[x_ch]:\n",
    "            # 根据长度决定颜色\n",
    "            color = 'yellow' if length >= 15 else 'red'\n",
    "            rect = plt.Rectangle((vmin, ymin), vmax-vmin, ymax-ymin, edgecolor=color, facecolor='none')\n",
    "            ax.add_patch(rect)\n",
    "\n",
    "    plt.title(f'FITS Slice and Structures at X Channel: {x_ch}')\n",
    "    if not os.path.exists(output_directory):\n",
    "        os.makedirs(output_directory)\n",
    "    output_path = os.path.join(output_directory, f'x_ch_{x_ch}.png')\n",
    "    plt.savefig(output_path)\n",
    "    plt.close()\n",
    "\n",
    "def process_all_channels(csv_path, fits_path, output_directory):\n",
    "    structures = read_structure_file(csv_path)\n",
    "    with fits.open(fits_path) as hdul:\n",
    "        max_x = hdul[0].data.shape[2]  # Assume the third dimension is X\n",
    "\n",
    "    for x_ch in range(max_x):\n",
    "        if x_ch in structures:  # 只处理有结构的x通道\n",
    "            save_fits_slice_with_structures(x_ch, fits_path, structures, output_directory)\n",
    "\n",
    "\n",
    "# 设置路径\n",
    "csv_path = '/Users/naoj306/Desktop/find/location/nonan_diff_1-99_3-3/location.csv'\n",
    "fits_path = \"/Users/naoj306/Desktop/DB/SFP/AquilaRift_12CO_21.7arcsec_vel0.1_sph_v1.0.fits\"\n",
    "output_directory = '/Users/naoj306/Desktop/find/images/1/'\n",
    "process_all_channels(csv_path, fits_path, output_directory)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "95172399da3016bc",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "plot all fila (x, ymin, ymax) on integrated xy\n",
    "(too big data, pass)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ddf25ecb50c6f74c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# from astropy.io import fits\n",
    "# from astropy.wcs import WCS\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# import pandas as pd\n",
    "# \n",
    "# def generate_and_save_summed_velocity_slices_with_structures(fits_name, output_path, csv_path):\n",
    "#     with fits.open(fits_name) as hdul:\n",
    "#         data = hdul[0].data\n",
    "#         header = hdul[0].header\n",
    "#         wcs = WCS(header).dropaxis(2)\n",
    "# \n",
    "#     # Check data integrity\n",
    "#     if np.all(data == 0):\n",
    "#         raise ValueError(\"Data contains only zeros.\")\n",
    "#     if np.isnan(data).any():\n",
    "#         print(\"Warning: Data contains NaNs, which will be ignored in the sum.\")\n",
    "# \n",
    "#     # Sum the data across all velocity channels\n",
    "#     summed_data = np.nansum(data, axis=0)  # use nansum to ignore NaNs\n",
    "# \n",
    "#     # Determine the dynamic range based on percentiles to handle extreme values\n",
    "#     vmin = np.percentile(summed_data, 1)   # Adjust this to include more of the data's lower range\n",
    "#     vmax = np.percentile(summed_data, 99)  # Adjust this to include more of the data's upper range\n",
    "#     print(f\"Using vmin={vmin} and vmax={vmax} for visualization.\")\n",
    "# \n",
    "#     df = pd.read_csv(csv_path)\n",
    "#     fig, ax = plt.subplots(1, 1, figsize=(8, 6))\n",
    "#     im = ax.imshow(summed_data, origin='lower', cmap='winter', aspect='auto', vmin=vmin, vmax=vmax)\n",
    "#     ax.set_title(\"Integrated over all velocities\")\n",
    "# \n",
    "#     for _, row in df.iterrows():\n",
    "#         x_coord = int(row['x channel'])\n",
    "#         ymin = int(row['ymin'])\n",
    "#         ymax = int(row['ymax'])\n",
    "#         ax.scatter([x_coord, x_coord], [ymin, ymax], color='yellow', s=1)\n",
    "# \n",
    "#     ra_axis = np.linspace(0, wcs.pixel_shape[0] - 1, num=5)\n",
    "#     dec_axis = np.linspace(0, wcs.pixel_shape[1] - 1, num=5)\n",
    "#     ra_pix, dec_pix = np.meshgrid(ra_axis, dec_axis)\n",
    "#     ra_deg, dec_deg = wcs.all_pix2world(ra_pix, dec_pix, 0)\n",
    "#     ax.set_xticks(ra_axis)\n",
    "#     ax.set_xticklabels([f\"{ra:.2f}\" for ra in ra_deg[0]])\n",
    "#     ax.set_yticks(dec_axis)\n",
    "#     ax.set_yticklabels([f\"{dec:.2f}\" for dec in dec_deg[:, 0]])\n",
    "# \n",
    "#     ax.set_xlabel(\"RA (degrees)\")\n",
    "#     ax.set_ylabel(\"Dec (degrees)\")\n",
    "#     cbar = plt.colorbar(im, ax=ax, pad=0.1)\n",
    "#     cbar.set_label('Integrated Temperature (K)', rotation=270, labelpad=15)\n",
    "#     plt.savefig(f\"{output_path}/on-xy-map.png\")\n",
    "#     plt.close()\n",
    "# \n",
    "# fits_name = \"/Users/naoj306/Desktop/DB/SFP/AquilaRift_12CO_21.7arcsec_vel0.1_sph_v1.0.fits\"\n",
    "# csv_path = '/Users/naoj306/Desktop/find/aquila_12/location/nonan_diff_1-99_3-3/location.csv'\n",
    "# output_path = \"/Users/naoj306/Desktop/find/aquila_12/location/nonan_diff_1-99_3-3/\" \n",
    "# generate_and_save_summed_velocity_slices_with_structures(fits_name, output_path, csv_path)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3c5a9a18eb4f3f6a",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "plot class=1 (len> ?) (x, ymin, ymax) on integrated xy"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5339ad7b09363ae"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from astropy.io import fits\n",
    "from astropy.wcs import WCS\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "def generate_and_save_summed_velocity_slices_with_structures(fits_name, output_path, csv_path):\n",
    "    \"\"\"\n",
    "    Generate an image by summing slices over all velocity channels, overlay structural data from a CSV file\n",
    "    for entries where class=1, as lines connecting (x, ymin) to (x, ymax), and save it to a specified path.\n",
    "    \"\"\"\n",
    "    with fits.open(fits_name) as hdul:\n",
    "        data = hdul[0].data.astype(np.float32)  # Ensure data type is float for handling NaNs\n",
    "        header = hdul[0].header\n",
    "        wcs = WCS(header).dropaxis(2)  # Drop the velocity dimension\n",
    "\n",
    "    if np.isnan(data).any():\n",
    "        print(\"Data contains NaNs, filling with zeros.\")\n",
    "        data = np.nan_to_num(data)  # Replace NaNs with zero if present\n",
    "\n",
    "    # Sum the data across all velocity channels\n",
    "    summed_data = np.sum(data, axis=0)\n",
    "\n",
    "    print(\"Summed Data Min:\", np.min(summed_data))\n",
    "    print(\"Summed Data Max:\", np.max(summed_data))\n",
    "\n",
    "    # Check if the summed data are properly computed\n",
    "    if np.all(summed_data == 0):\n",
    "        raise ValueError(\"Data contains only zeros.\")\n",
    "    if np.isnan(summed_data).any():\n",
    "        print(\"Warning: Summed data contains NaNs, which will be ignored in the visualization.\")\n",
    "\n",
    "    # Determine the dynamic range based on percentiles to handle extreme values\n",
    "    vmin = np.percentile(summed_data, 1)   # Adjust this to include more of the data's lower range\n",
    "    vmax = np.percentile(summed_data, 99)  # Adjust this to include more of the data's upper range\n",
    "    print(f\"Using vmin={vmin} and vmax={vmax} for visualization.\")\n",
    "    \n",
    "    df = pd.read_csv(csv_path)\n",
    "    df = df[df['class'] == 1]  # Filter to include only rows where class equals 1\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(8, 6))\n",
    "    im = ax.imshow(summed_data, origin='lower', cmap='winter', aspect='auto', vmin=vmin, vmax=vmax)\n",
    "    ax.set_title(\"Integrated over all velocities\")\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        x_coord = int(row['x channel'])\n",
    "        ymin = int(row['ymin'])\n",
    "        ymax = int(row['ymax'])\n",
    "        ax.scatter([x_coord, x_coord], [ymin, ymax], color='yellow', s=0.5)\n",
    "\n",
    "    # Configure axes with WCS coordinates\n",
    "    ra_axis = np.linspace(0, wcs.pixel_shape[0] - 1, num=5)\n",
    "    dec_axis = np.linspace(0, wcs.pixel_shape[1] - 1, num=5)\n",
    "    ra_pix, dec_pix = np.meshgrid(ra_axis, dec_axis)\n",
    "    ra_deg, dec_deg = wcs.all_pix2world(ra_pix, dec_pix, 0)\n",
    "    ax.set_xticks(ra_axis)\n",
    "    ax.set_xticklabels([f\"{ra:.2f}\" for ra in ra_deg[0]])\n",
    "    ax.set_yticks(dec_axis)\n",
    "    ax.set_yticklabels([f\"{dec:.2f}\" for dec in dec_deg[:, 0]])\n",
    "\n",
    "    ax.set_xlabel(\"RA (degrees)\")\n",
    "    ax.set_ylabel(\"Dec (degrees)\")\n",
    "\n",
    "    cbar = plt.colorbar(im, ax=ax, pad=0.1)\n",
    "    cbar.set_label('Integrated Temperature (K)', rotation=270, labelpad=15)\n",
    "\n",
    "    plt.savefig(f\"{output_path}/on-xy-map-30.png\")\n",
    "    plt.close()\n",
    "\n",
    "fits_name = \"/Users/naoj306/Desktop/DB/SFP/AquilaRift_12CO_21.7arcsec_vel0.1_sph_v1.0.fits\"\n",
    "csv_path = '/Users/naoj306/Desktop/find/aquila_12/location/nonan_diff_1-99_3-3/location-30.csv'\n",
    "output_path = \"/Users/naoj306/Desktop/find/aquila_12/location/nonan_diff_1-99_3-3/\"\n",
    "generate_and_save_summed_velocity_slices_with_structures(fits_name, output_path, csv_path)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a5827645c9450fb4",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "plot class=1 (x, ymin, ymax) on integrated xy, (x-5, x+5) have neighbor only"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "25f02b45f386232b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from astropy.io import fits\n",
    "from astropy.wcs import WCS\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "def generate_and_save_summed_velocity_slices_with_structures(fits_name, output_path, csv_path):\n",
    "    \"\"\"\n",
    "    Generate an image by summing slices over all velocity channels, overlay structural data from a CSV file\n",
    "    for entries where class=1, as lines connecting (x, ymin) to (x, ymax), and save it to a specified path.\n",
    "    \"\"\"\n",
    "    with fits.open(fits_name) as hdul:\n",
    "        data = hdul[0].data.astype(np.float32)  # Ensure data type is float for handling NaNs\n",
    "        header = hdul[0].header\n",
    "        wcs = WCS(header).dropaxis(2)  # Drop the velocity dimension\n",
    "\n",
    "    if np.isnan(data).any():\n",
    "        print(\"Data contains NaNs, filling with zeros.\")\n",
    "        data = np.nan_to_num(data)  # Replace NaNs with zero if present\n",
    "\n",
    "    # Sum the data across all velocity channels\n",
    "    summed_data = np.sum(data, axis=0)\n",
    "\n",
    "    print(\"Summed Data Min:\", np.min(summed_data))\n",
    "    print(\"Summed Data Max:\", np.max(summed_data))\n",
    "\n",
    "    # Check if the summed data are properly computed\n",
    "    if np.all(summed_data == 0):\n",
    "        raise ValueError(\"Data contains only zeros.\")\n",
    "    if np.isnan(summed_data).any():\n",
    "        print(\"Warning: Summed data contains NaNs, which will be ignored in the visualization.\")\n",
    "\n",
    "    # Determine the dynamic range based on percentiles to handle extreme values\n",
    "    vmin = np.percentile(summed_data, 1)   # Adjust this to include more of the data's lower range\n",
    "    vmax = np.percentile(summed_data, 99)  # Adjust this to include more of the data's upper range\n",
    "    print(f\"Using vmin={vmin} and vmax={vmax} for visualization.\")\n",
    "    \n",
    "    df = pd.read_csv(csv_path)\n",
    "    df = df[df['class'] == 1]\n",
    "    df.sort_values('x channel', inplace=True)\n",
    "\n",
    "    # 使用相同的代码定义 has_adjacent 函数\n",
    "    def has_adjacent(row, df):\n",
    "        x_center = int(row['x channel'])\n",
    "        x_range = range(x_center - 5, x_center + 6)\n",
    "        ymin = row['ymin']\n",
    "        ymax = row['ymax']\n",
    "        adjacent_df = df[df['x channel'].isin(x_range)]\n",
    "        for _, adj_row in adjacent_df.iterrows():\n",
    "            if adj_row['x channel'] != x_center and (adj_row['ymin'] <= ymax and adj_row['ymax'] >= ymin):\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    df['has_adjacent'] = df.apply(lambda row: has_adjacent(row, df), axis=1)\n",
    "    df_adjacent = df[df['has_adjacent'] == True]\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(8, 6))\n",
    "    im = ax.imshow(summed_data, origin='lower', cmap='winter', aspect='auto', vmin=vmin, vmax=vmax)\n",
    "    ax.set_title(\"Integrated over all velocities with adjacent structures\")\n",
    "\n",
    "    for _, row in df_adjacent.iterrows():\n",
    "        x_coord = [row['x channel'], row['x channel']]\n",
    "        y_coords = [row['ymin'], row['ymax']]\n",
    "        ax.scatter(x_coord, y_coords, color='yellow', s=0.5)\n",
    "        \n",
    "    # Configure axes with WCS coordinates\n",
    "    ra_axis = np.linspace(0, wcs.pixel_shape[0] - 1, num=5)\n",
    "    dec_axis = np.linspace(0, wcs.pixel_shape[1] - 1, num=5)\n",
    "    ra_pix, dec_pix = np.meshgrid(ra_axis, dec_axis)\n",
    "    ra_deg, dec_deg = wcs.all_pix2world(ra_pix, dec_pix, 0)\n",
    "    ax.set_xticks(ra_axis)\n",
    "    ax.set_xticklabels([f\"{ra:.2f}\" for ra in ra_deg[0]])\n",
    "    ax.set_yticks(dec_axis)\n",
    "    ax.set_yticklabels([f\"{dec:.2f}\" for dec in dec_deg[:, 0]])\n",
    "    ax.set_xlabel(\"RA (degrees)\")\n",
    "    ax.set_ylabel(\"Dec (degrees)\")\n",
    "    cbar = plt.colorbar(im, ax=ax, pad=0.1)\n",
    "    cbar.set_label('Integrated Temperature (K)', rotation=270, labelpad=15)\n",
    "\n",
    "    plt.savefig(f\"{output_path}/on-xy-map-30-cluster.png\", dpi=100)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "fits_name = \"/Users/naoj306/Desktop/DB/SFP/AquilaRift_12CO_21.7arcsec_vel0.1_sph_v1.0.fits\"\n",
    "csv_path = '/Users/naoj306/Desktop/find/aquila_12/location/nonan_diff_1-99_3-3/location-30.csv'\n",
    "output_path = \"/Users/naoj306/Desktop/find/aquila_12/location/nonan_diff_1-99_3-3/\"\n",
    "generate_and_save_summed_velocity_slices_with_structures(fits_name, output_path, csv_path)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c0e929db0a9e7ce2",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "7deb84421fcdf6a9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
